#  Decoding Fake Narratives in Spreading Hateful Stories (Faux-Hate)
Task A - Binary Faux-Hate Detection
Participants will receive a dataset containing text samples, each labeled with:

Fake: Binary label indicating if the content is fake (1) or real (0).
Hate: Binary label indicating if the content is hate speech (1) or not (0).
The objective of this sub-task is to develop a single multi-tasking model that outputs both the fake and hate labels for each text sample.

Task B - Target and Severity Prediction
Participants will receive a dataset containing text samples, each labeled with:

Target: Categorical label indicating the target of the content (Individual (I), Organization (O), and Religion (R)).
Severity: Categorical label indicating the severity of the content (Low (L), Medium (M), and High (H)).
The objective of this sub-task is to develop a single model that generates both the target and severity labels for a given text sample.


```
@proceedings{icon-2024-faux-hate-overview,
    title = "Proceedings of the 21st International Conference on Natural Language Processing (ICON): Shared Task on Decoding Fake Narratives in Spreading Hateful Stories (Faux-Hate)",
    editor = "Biradar, Shankar  and
           Reddy Kasu, Sai Kartheek  and
           Saumya, Sunil and
       Akhtar, Md. Shad",
    month = Dec,
    year = "2024",
    address = "AU-KBC Research Centre, MIT College, India",
    publisher = "Association for Computational Linguistics",
}
```
