{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from gensim.models import Word2Vec\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import csv\n",
    "import regex as re\n",
    "import re\n",
    "import string\n",
    "import pennylane as qml\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Train_Task_B_Updated.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Hate</th>\n",
       "      <th>Target</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5723</td>\n",
       "      <td>@sudhirchaudhary Abhi tak 2000 ke note me mujh...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2338</td>\n",
       "      <td>@Gulamane_raza @MustakimRazvi Abe katiye tumse...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1579</td>\n",
       "      <td>@RajatSharmaLive Ye sab sazish hai....bina sam...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6524</td>\n",
       "      <td>abe jao tum to dasko pahle hi fash gye the jab...</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7618</td>\n",
       "      <td>Ab ye afbah kaun faila Raha hai ki Shahhen bag...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5077</td>\n",
       "      <td>@FilmyKhichdii Nahi sudhar sakta tu.... Waise ...</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5342</td>\n",
       "      <td>Hindenburg ko America ke 2 Bank ki gadbadi nah...</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1451</td>\n",
       "      <td>@AcharyaPramodk Agar tum maan lo ki tabligi ja...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4975</td>\n",
       "      <td>@TweetAbhishekA Inme se kahiyoun ke pati, pita...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7108</td>\n",
       "      <td>..magar accident mein toh na jane kitne muslim...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                              Tweet  Hate Target  \\\n",
       "0  5723  @sudhirchaudhary Abhi tak 2000 ke note me mujh...     0    NaN   \n",
       "1  2338  @Gulamane_raza @MustakimRazvi Abe katiye tumse...     1      O   \n",
       "2  1579  @RajatSharmaLive Ye sab sazish hai....bina sam...     1      O   \n",
       "3  6524  abe jao tum to dasko pahle hi fash gye the jab...     1      I   \n",
       "4  7618  Ab ye afbah kaun faila Raha hai ki Shahhen bag...     0    NaN   \n",
       "5  5077  @FilmyKhichdii Nahi sudhar sakta tu.... Waise ...     1      R   \n",
       "6  5342  Hindenburg ko America ke 2 Bank ki gadbadi nah...     1      I   \n",
       "7  1451  @AcharyaPramodk Agar tum maan lo ki tabligi ja...     1      O   \n",
       "8  4975  @TweetAbhishekA Inme se kahiyoun ke pati, pita...     1      O   \n",
       "9  7108  ..magar accident mein toh na jane kitne muslim...     0    NaN   \n",
       "\n",
       "  Severity  \n",
       "0      NaN  \n",
       "1        H  \n",
       "2        M  \n",
       "3        L  \n",
       "4      NaN  \n",
       "5        L  \n",
       "6        L  \n",
       "7        L  \n",
       "8        L  \n",
       "9      NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Tweet', 'Hate', 'Target', 'Severity'], dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Hate.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean all data\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    try:\n",
    "        text = re.sub('(\\&amp\\;)', '', text)\n",
    "        # removing any usernames\n",
    "        text = re.sub('(@[^\\s]+)', '', text)\n",
    "        # removing any hashtags\n",
    "        text = re.sub('(#[^\\s]+)', '', text)\n",
    "        \n",
    "        text = re.sub(r'[^a-zA-Z0-9\\s]', '', text).lower()\n",
    "        # remove `rt` for retweet\n",
    "        text = re.sub('(rt)', '', text)\n",
    "        # string.punctuation is a string of all punctuation marks\n",
    "        # so this gets rid of all punctuation\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "        # getting rid of `httptco`\n",
    "        text = re.sub('(httptco)', '', text)\n",
    "    except:\n",
    "        text = \"None\"\n",
    "\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       @sudhirchaudhary Abhi tak 2000 ke note me mujh...\n",
       "1       @Gulamane_raza @MustakimRazvi Abe katiye tumse...\n",
       "2       @RajatSharmaLive Ye sab sazish hai....bina sam...\n",
       "3       abe jao tum to dasko pahle hi fash gye the jab...\n",
       "4       Ab ye afbah kaun faila Raha hai ki Shahhen bag...\n",
       "                              ...                        \n",
       "6391    @team_hyv Pathaan part 2 bhi aa rha hai, boyco...\n",
       "6392    @amitku1047 @bordiasanjay @izeenatrana @RahulG...\n",
       "6393    @HusainSahadal Sachaee ladaee hoti h hamare de...\n",
       "6394                  Hahaha hahaha kejurdin ððð\n",
       "6395    Aswini upadhyay aap desh ko grhyudh ke raste p...\n",
       "Name: Tweet, Length: 6396, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet'] = df.Tweet.astype('str')\n",
    "df.Tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweets'] = df['Tweet'].apply(round1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Hate</th>\n",
       "      <th>Target</th>\n",
       "      <th>Severity</th>\n",
       "      <th>clean_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@sudhirchaudhary Abhi tak 2000 ke note me mujh...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abhi tak 2000 ke note me mujhe gps nano chip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Gulamane_raza @MustakimRazvi Abe katiye tumse...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>H</td>\n",
       "      <td>abe katiye tumse kuch huaa toh jata nahi bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@RajatSharmaLive Ye sab sazish hai....bina sam...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>ye sab sazish haibina saman ke koi kaise apne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abe jao tum to dasko pahle hi fash gye the jab...</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>L</td>\n",
       "      <td>abe jao tum to dasko pahle hi fash gye the jab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ab ye afbah kaun faila Raha hai ki Shahhen bag...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ab ye afbah kaun faila raha hai ki shahhen bag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>@team_hyv Pathaan part 2 bhi aa rha hai, boyco...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>pathaan pa 2 bhi aa rha hai boycott karna nhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>@amitku1047 @bordiasanjay @izeenatrana @RahulG...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>L</td>\n",
       "      <td>hindenburg adani pe kuchh bolta hai tto ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>@HusainSahadal Sachaee ladaee hoti h hamare de...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>L</td>\n",
       "      <td>sachaee ladaee hoti h hamare desh me tablighi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>Hahaha hahaha kejurdin ððð</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hahaha hahaha kejurdin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>Aswini upadhyay aap desh ko grhyudh ke raste p...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aswini upadhyay aap desh ko grhyudh ke raste p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6396 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Hate Target Severity  \\\n",
       "0     @sudhirchaudhary Abhi tak 2000 ke note me mujh...     0    NaN      NaN   \n",
       "1     @Gulamane_raza @MustakimRazvi Abe katiye tumse...     1      O        H   \n",
       "2     @RajatSharmaLive Ye sab sazish hai....bina sam...     1      O        M   \n",
       "3     abe jao tum to dasko pahle hi fash gye the jab...     1      I        L   \n",
       "4     Ab ye afbah kaun faila Raha hai ki Shahhen bag...     0    NaN      NaN   \n",
       "...                                                 ...   ...    ...      ...   \n",
       "6391  @team_hyv Pathaan part 2 bhi aa rha hai, boyco...     1      O        M   \n",
       "6392  @amitku1047 @bordiasanjay @izeenatrana @RahulG...     1      O        L   \n",
       "6393  @HusainSahadal Sachaee ladaee hoti h hamare de...     1      O        L   \n",
       "6394                Hahaha hahaha kejurdin ððð     0    NaN      NaN   \n",
       "6395  Aswini upadhyay aap desh ko grhyudh ke raste p...     0    NaN      NaN   \n",
       "\n",
       "                                           clean_tweets  \n",
       "0      abhi tak 2000 ke note me mujhe gps nano chip ...  \n",
       "1       abe katiye tumse kuch huaa toh jata nahi bas...  \n",
       "2      ye sab sazish haibina saman ke koi kaise apne...  \n",
       "3     abe jao tum to dasko pahle hi fash gye the jab...  \n",
       "4     ab ye afbah kaun faila raha hai ki shahhen bag...  \n",
       "...                                                 ...  \n",
       "6391   pathaan pa 2 bhi aa rha hai boycott karna nhi...  \n",
       "6392      hindenburg adani pe kuchh bolta hai tto ke...  \n",
       "6393   sachaee ladaee hoti h hamare desh me tablighi...  \n",
       "6394                            hahaha hahaha kejurdin   \n",
       "6395  aswini upadhyay aap desh ko grhyudh ke raste p...  \n",
       "\n",
       "[6396 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(sentence):\n",
    "    # Split the sentence into words based on whitespace\n",
    "    words = sentence.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"clean_tweets\"].apply(tokenise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [abhi, tak, 2000, ke, note, me, mujhe, gps, na...\n",
       "1       [abe, katiye, tumse, kuch, huaa, toh, jata, na...\n",
       "2       [ye, sab, sazish, haibina, saman, ke, koi, kai...\n",
       "3       [abe, jao, tum, to, dasko, pahle, hi, fash, gy...\n",
       "4       [ab, ye, afbah, kaun, faila, raha, hai, ki, sh...\n",
       "                              ...                        \n",
       "6391    [pathaan, pa, 2, bhi, aa, rha, hai, boycott, k...\n",
       "6392    [hindenburg, adani, pe, kuchh, bolta, hai, tto...\n",
       "6393    [sachaee, ladaee, hoti, h, hamare, desh, me, t...\n",
       "6394                           [hahaha, hahaha, kejurdin]\n",
       "6395    [aswini, upadhyay, aap, desh, ko, grhyudh, ke,...\n",
       "Name: tokens, Length: 6396, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tokens\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'O' 'I' 'R']\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the data to get labels\n",
    "# Initialize LabelEncoder\n",
    "label_encoder1 = LabelEncoder()\n",
    "\n",
    "targets = df['Target']\n",
    "\n",
    "print(targets.unique())\n",
    "data_labels = label_encoder1.fit_transform(targets)\n",
    "num_classes = len(np.unique(data_labels))\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "one_hot_vectors_targets = np.eye(num_classes)[data_labels]\n",
    "df['Target_labels'] = data_labels\n",
    "df['Target_class'] = list(one_hot_vectors_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan 'H' 'M' 'L']\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "sev = df['Severity']\n",
    "\n",
    "print(sev.unique())\n",
    "data_labels = label_encoder.fit_transform(sev)\n",
    "num_classes = len(np.unique(data_labels))\n",
    "\n",
    "# Convert to one-hot encoding\n",
    "one_hot_vectors_sev = np.eye(num_classes)[data_labels]\n",
    "df['Sev_labels'] = data_labels\n",
    "df['Sev_class'] = list(one_hot_vectors_sev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Hate</th>\n",
       "      <th>Target</th>\n",
       "      <th>Severity</th>\n",
       "      <th>clean_tweets</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Target_labels</th>\n",
       "      <th>Target_class</th>\n",
       "      <th>Sev_labels</th>\n",
       "      <th>Sev_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@sudhirchaudhary Abhi tak 2000 ke note me mujh...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>abhi tak 2000 ke note me mujhe gps nano chip ...</td>\n",
       "      <td>[abhi, tak, 2000, ke, note, me, mujhe, gps, na...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Gulamane_raza @MustakimRazvi Abe katiye tumse...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>H</td>\n",
       "      <td>abe katiye tumse kuch huaa toh jata nahi bas...</td>\n",
       "      <td>[abe, katiye, tumse, kuch, huaa, toh, jata, na...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@RajatSharmaLive Ye sab sazish hai....bina sam...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>ye sab sazish haibina saman ke koi kaise apne...</td>\n",
       "      <td>[ye, sab, sazish, haibina, saman, ke, koi, kai...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abe jao tum to dasko pahle hi fash gye the jab...</td>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>L</td>\n",
       "      <td>abe jao tum to dasko pahle hi fash gye the jab...</td>\n",
       "      <td>[abe, jao, tum, to, dasko, pahle, hi, fash, gy...</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0, 0.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ab ye afbah kaun faila Raha hai ki Shahhen bag...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ab ye afbah kaun faila raha hai ki shahhen bag...</td>\n",
       "      <td>[ab, ye, afbah, kaun, faila, raha, hai, ki, sh...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>@team_hyv Pathaan part 2 bhi aa rha hai, boyco...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>pathaan pa 2 bhi aa rha hai boycott karna nhi...</td>\n",
       "      <td>[pathaan, pa, 2, bhi, aa, rha, hai, boycott, k...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>@amitku1047 @bordiasanjay @izeenatrana @RahulG...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>L</td>\n",
       "      <td>hindenburg adani pe kuchh bolta hai tto ke...</td>\n",
       "      <td>[hindenburg, adani, pe, kuchh, bolta, hai, tto...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>@HusainSahadal Sachaee ladaee hoti h hamare de...</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>L</td>\n",
       "      <td>sachaee ladaee hoti h hamare desh me tablighi...</td>\n",
       "      <td>[sachaee, ladaee, hoti, h, hamare, desh, me, t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>Hahaha hahaha kejurdin ððð</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hahaha hahaha kejurdin</td>\n",
       "      <td>[hahaha, hahaha, kejurdin]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>Aswini upadhyay aap desh ko grhyudh ke raste p...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aswini upadhyay aap desh ko grhyudh ke raste p...</td>\n",
       "      <td>[aswini, upadhyay, aap, desh, ko, grhyudh, ke,...</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0, 0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6396 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweet  Hate Target Severity  \\\n",
       "0     @sudhirchaudhary Abhi tak 2000 ke note me mujh...     0    NaN      NaN   \n",
       "1     @Gulamane_raza @MustakimRazvi Abe katiye tumse...     1      O        H   \n",
       "2     @RajatSharmaLive Ye sab sazish hai....bina sam...     1      O        M   \n",
       "3     abe jao tum to dasko pahle hi fash gye the jab...     1      I        L   \n",
       "4     Ab ye afbah kaun faila Raha hai ki Shahhen bag...     0    NaN      NaN   \n",
       "...                                                 ...   ...    ...      ...   \n",
       "6391  @team_hyv Pathaan part 2 bhi aa rha hai, boyco...     1      O        M   \n",
       "6392  @amitku1047 @bordiasanjay @izeenatrana @RahulG...     1      O        L   \n",
       "6393  @HusainSahadal Sachaee ladaee hoti h hamare de...     1      O        L   \n",
       "6394                Hahaha hahaha kejurdin ððð     0    NaN      NaN   \n",
       "6395  Aswini upadhyay aap desh ko grhyudh ke raste p...     0    NaN      NaN   \n",
       "\n",
       "                                           clean_tweets  \\\n",
       "0      abhi tak 2000 ke note me mujhe gps nano chip ...   \n",
       "1       abe katiye tumse kuch huaa toh jata nahi bas...   \n",
       "2      ye sab sazish haibina saman ke koi kaise apne...   \n",
       "3     abe jao tum to dasko pahle hi fash gye the jab...   \n",
       "4     ab ye afbah kaun faila raha hai ki shahhen bag...   \n",
       "...                                                 ...   \n",
       "6391   pathaan pa 2 bhi aa rha hai boycott karna nhi...   \n",
       "6392      hindenburg adani pe kuchh bolta hai tto ke...   \n",
       "6393   sachaee ladaee hoti h hamare desh me tablighi...   \n",
       "6394                            hahaha hahaha kejurdin    \n",
       "6395  aswini upadhyay aap desh ko grhyudh ke raste p...   \n",
       "\n",
       "                                                 tokens  Target_labels  \\\n",
       "0     [abhi, tak, 2000, ke, note, me, mujhe, gps, na...              3   \n",
       "1     [abe, katiye, tumse, kuch, huaa, toh, jata, na...              1   \n",
       "2     [ye, sab, sazish, haibina, saman, ke, koi, kai...              1   \n",
       "3     [abe, jao, tum, to, dasko, pahle, hi, fash, gy...              0   \n",
       "4     [ab, ye, afbah, kaun, faila, raha, hai, ki, sh...              3   \n",
       "...                                                 ...            ...   \n",
       "6391  [pathaan, pa, 2, bhi, aa, rha, hai, boycott, k...              1   \n",
       "6392  [hindenburg, adani, pe, kuchh, bolta, hai, tto...              1   \n",
       "6393  [sachaee, ladaee, hoti, h, hamare, desh, me, t...              1   \n",
       "6394                         [hahaha, hahaha, kejurdin]              3   \n",
       "6395  [aswini, upadhyay, aap, desh, ko, grhyudh, ke,...              3   \n",
       "\n",
       "              Target_class  Sev_labels             Sev_class  \n",
       "0     [0.0, 0.0, 0.0, 1.0]           3  [0.0, 0.0, 0.0, 1.0]  \n",
       "1     [0.0, 1.0, 0.0, 0.0]           0  [1.0, 0.0, 0.0, 0.0]  \n",
       "2     [0.0, 1.0, 0.0, 0.0]           2  [0.0, 0.0, 1.0, 0.0]  \n",
       "3     [1.0, 0.0, 0.0, 0.0]           1  [0.0, 1.0, 0.0, 0.0]  \n",
       "4     [0.0, 0.0, 0.0, 1.0]           3  [0.0, 0.0, 0.0, 1.0]  \n",
       "...                    ...         ...                   ...  \n",
       "6391  [0.0, 1.0, 0.0, 0.0]           2  [0.0, 0.0, 1.0, 0.0]  \n",
       "6392  [0.0, 1.0, 0.0, 0.0]           1  [0.0, 1.0, 0.0, 0.0]  \n",
       "6393  [0.0, 1.0, 0.0, 0.0]           1  [0.0, 1.0, 0.0, 0.0]  \n",
       "6394  [0.0, 0.0, 0.0, 1.0]           3  [0.0, 0.0, 0.0, 1.0]  \n",
       "6395  [0.0, 0.0, 0.0, 1.0]           3  [0.0, 0.0, 0.0, 1.0]  \n",
       "\n",
       "[6396 rows x 10 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(df['tokens'], vector_size=150, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('kisi', 0.999377965927124), ('lekin', 0.9991707801818848), ('media', 0.9991361498832703), ('aap', 0.999123752117157), ('matlab', 0.9990874528884888), ('mar', 0.9990548491477966), ('fir', 0.999009370803833), ('he', 0.9989848732948303), ('ham', 0.9989730715751648), ('toh', 0.9989641308784485)]\n"
     ]
    }
   ],
   "source": [
    "word_vector = w2v_model.wv.most_similar(\"muslim\", topn=10)\n",
    "print(word_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec100.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_vector(sentence, model):\n",
    "    # Tokenize the sentence into words\n",
    "    words = tokenise(sentence)\n",
    "    \n",
    "    # Filter out words that are not in the Word2Vec vocabulary\n",
    "    words = [word for word in words if word in model.wv.key_to_index]\n",
    "    \n",
    "    # If no words in the sentence are in the vocabulary, return a zero vector\n",
    "    if not words:\n",
    "        return np.zeros(model.vector_size)\n",
    "    \n",
    "    # Compute the mean of the word vectors for each word in the sentence\n",
    "    vector = np.mean([model.wv[word] for word in words], axis=0)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"word2vec\"] = df['clean_tweets'].apply(lambda x: sentence_vector(x,w2v_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.045394596, -0.13685577, 0.13742019, -0.1860...\n",
       "1       [0.14256448, -0.23133567, 0.11076895, 0.009853...\n",
       "2       [0.16091214, -0.25882146, 0.12112002, 0.006225...\n",
       "3       [0.13291161, -0.22470413, 0.10155532, 0.018162...\n",
       "4       [0.14855647, -0.24347338, 0.112669766, 0.00736...\n",
       "                              ...                        \n",
       "6391    [0.10991704, -0.18863693, 0.080379084, 0.01619...\n",
       "6392    [0.13340177, -0.22549446, 0.09710176, 0.012762...\n",
       "6393    [0.20076437, -0.31039825, 0.16787705, 0.010148...\n",
       "6394    [0.004504125, -0.016211307, 0.010741017, -0.00...\n",
       "6395    [0.15735605, -0.2549452, 0.114094734, 0.014221...\n",
       "Name: word2vec, Length: 6396, dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word2vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweet               0\n",
       "Hate                0\n",
       "Target           2295\n",
       "Severity         2295\n",
       "clean_tweets        0\n",
       "tokens              0\n",
       "Target_labels       0\n",
       "Target_class        0\n",
       "Sev_labels          0\n",
       "Sev_class           0\n",
       "word2vec            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 5\n",
    "n_layers = 1\n",
    "dev = qml.device(\"lightning.qubit\", wires=n_qubits)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def quantum_nn(inputs, weights):\n",
    "\n",
    "  # Input Embedding\n",
    "  qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "\n",
    "  qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "\n",
    "  return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def quantum_nn2(inputs, weights):\n",
    "\n",
    "  # Input Embedding\n",
    "  qml.AngleEmbedding(inputs, wires=range(n_qubits))\n",
    "\n",
    "  qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n",
    "\n",
    "  return [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_layers = 1\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}\n",
    "\n",
    "qlayer = qml.qnn.TorchLayer(quantum_nn, weight_shapes)\n",
    "qlayer2 = qml.qnn.TorchLayer(quantum_nn2, weight_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNN_model(nn.Module):\n",
    "    def __init__(self, input_size, qlayer, n_qubits, output_size):\n",
    "        super(QNN_model, self).__init__()\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc2 = nn.Linear(input_size, input_size // 10)\n",
    "        self.fc3 = nn.Linear(input_size // 10, input_size // 20)\n",
    "        self.fc4 = nn.Linear(input_size // 20, n_qubits)\n",
    "\n",
    "        # Quantum layer\n",
    "        self.qlayer = qlayer\n",
    "\n",
    "        # Output layers for target and severity\n",
    "        self.target = nn.Linear(n_qubits, output_size)\n",
    "        self.severity = nn.Linear(n_qubits, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through fully connected layers with ReLU activation\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "\n",
    "        # Quantum layer processing\n",
    "        x = self.qlayer(x)\n",
    "\n",
    "        # Output layers (return raw logits)\n",
    "        x_severity = self.severity(x)  # Shape: [batch_size, output_size]\n",
    "        x_target = self.target(x)      # Shape: [batch_size, output_size]\n",
    "\n",
    "        return x_target, x_severity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qmodel = QNN_model(150,qlayer,n_qubits,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6396 entries, 0 to 6395\n",
      "Data columns (total 11 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Tweet          6396 non-null   object\n",
      " 1   Hate           6396 non-null   int64 \n",
      " 2   Target         4101 non-null   object\n",
      " 3   Severity       4101 non-null   object\n",
      " 4   clean_tweets   6396 non-null   object\n",
      " 5   tokens         6396 non-null   object\n",
      " 6   Target_labels  6396 non-null   int32 \n",
      " 7   Target_class   6396 non-null   object\n",
      " 8   Sev_labels     6396 non-null   int32 \n",
      " 9   Sev_class      6396 non-null   object\n",
      " 10  word2vec       6396 non-null   object\n",
      "dtypes: int32(2), int64(1), object(8)\n",
      "memory usage: 499.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch of vectors (shape): torch.Size([16, 150])\n",
      "Batch of target labels: torch.Size([16, 4])\n",
      "Batch of severity labels: torch.Size([16, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "# Define a custom Dataset class\n",
    "class Word2VecDataset2(Dataset):\n",
    "    def __init__(self, dataframe, target_class, target_class2):\n",
    "        \"\"\"\n",
    "        Custom Dataset for Word2Vec inputs with multi-target labels.\n",
    "\n",
    "        Args:\n",
    "        - dataframe (pd.DataFrame): Input data containing word2vec vectors and target labels.\n",
    "        - target_class (str): Column name for the primary target.\n",
    "        - target_class2 (str): Column name for the secondary target.\n",
    "        \"\"\"\n",
    "        self.data = dataframe\n",
    "        self.target = target_class\n",
    "        self.severity = target_class2\n",
    "\n",
    "        # Validate columns\n",
    "        required_columns = ['word2vec', self.target, self.severity]\n",
    "        for col in required_columns:\n",
    "            if col not in dataframe.columns:\n",
    "                raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Extract the input vector and labels\n",
    "        vector = torch.tensor(self.data.iloc[index]['word2vec'], dtype=torch.float32)\n",
    "        label_tar = torch.tensor(self.data.iloc[index][self.target], dtype=torch.float32)  # Classification targets\n",
    "        label_sev = torch.tensor(self.data.iloc[index][self.severity], dtype=torch.float32)\n",
    "        return vector, label_tar, label_sev\n",
    "\n",
    "# Create the dataset and dataloader\n",
    "target1 = \"Target_class\"  # Replace with your column name for target\n",
    "target2 = \"Sev_class\"     # Replace with your column name for severity\n",
    "dataset = Word2VecDataset2(df, target1, target2)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Example usage\n",
    "for vectors, labels1, labels2 in dataloader:\n",
    "    print(\"Batch of vectors (shape):\", vectors.shape)\n",
    "    print(\"Batch of target labels:\", labels1.shape)\n",
    "    print(\"Batch of severity labels:\", labels2.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 46.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 2.6688, Target Accuracy: 0.3568, Severity Accuracy: 0.3327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 49.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Loss: 2.5803, Target Accuracy: 0.3721, Severity Accuracy: 0.3588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Loss: 2.5692, Target Accuracy: 0.4234, Severity Accuracy: 0.3588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Loss: 2.5545, Target Accuracy: 0.4401, Severity Accuracy: 0.3588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 51.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Loss: 2.5080, Target Accuracy: 0.5011, Severity Accuracy: 0.3816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 51.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Loss: 2.4232, Target Accuracy: 0.5219, Severity Accuracy: 0.4240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 49.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Loss: 2.3784, Target Accuracy: 0.5242, Severity Accuracy: 0.4279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 51.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Loss: 2.3650, Target Accuracy: 0.5238, Severity Accuracy: 0.4306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 50.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Loss: 2.3556, Target Accuracy: 0.5261, Severity Accuracy: 0.4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 50.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Loss: 2.3524, Target Accuracy: 0.5264, Severity Accuracy: 0.4332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Loss: 2.3500, Target Accuracy: 0.5272, Severity Accuracy: 0.4353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Loss: 2.3490, Target Accuracy: 0.5253, Severity Accuracy: 0.4334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Loss: 2.3481, Target Accuracy: 0.5261, Severity Accuracy: 0.4359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 47.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Loss: 2.3470, Target Accuracy: 0.5256, Severity Accuracy: 0.4337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 46.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Loss: 2.3455, Target Accuracy: 0.5288, Severity Accuracy: 0.4334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 48.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Loss: 2.3479, Target Accuracy: 0.5250, Severity Accuracy: 0.4339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 50.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Loss: 2.3459, Target Accuracy: 0.5283, Severity Accuracy: 0.4348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 51.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Loss: 2.3444, Target Accuracy: 0.5245, Severity Accuracy: 0.4361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:08<00:00, 49.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Loss: 2.3435, Target Accuracy: 0.5277, Severity Accuracy: 0.4354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:07<00:00, 51.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Loss: 2.3429, Target Accuracy: 0.5272, Severity Accuracy: 0.4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import csv\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(Qmodel.parameters(), lr=0.0005)\n",
    "\n",
    "filename = 'results_target.csv'\n",
    "\n",
    "# Write CSV Header\n",
    "with open(filename, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Epoch', 'Loss', 'Target Accuracy', 'Severity Accuracy'])\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    Qmodel.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct_tar = 0\n",
    "    correct_sev = 0\n",
    "    total = 0\n",
    "\n",
    "    for inputs, labels_tar, labels_sev in tqdm(dataloader):\n",
    "        # Move data to the appropriate device (e.g., CPU/GPU)\n",
    "        inputs, labels_tar, labels_sev = inputs.to(device), labels_tar.to(device), labels_sev.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs_tar, outputs_sev = Qmodel(inputs)\n",
    "        # print(outputs_sev.shape)\n",
    "        loss1 = criterion(outputs_tar, labels_tar)\n",
    "        loss2 = criterion(outputs_sev, labels_sev)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        # Predictions and accuracy for each target\n",
    "        # labels_tar = labels_tar.view(-1)  # Shape: [batch_size]\n",
    "        # labels_sev = labels_sev.view(-1)  # Shape: [batch_size]\n",
    "        _, labels_tar = torch.max(labels_tar, dim=1)\n",
    "        _, labels_sev = torch.max(labels_sev, dim=1)\n",
    "\n",
    "        # Predictions\n",
    "        _, predicted_tar = torch.max(outputs_tar, dim=1)\n",
    "        _, predicted_sev = torch.max(outputs_sev, dim=1)\n",
    "\n",
    "        # Update correct counts\n",
    "        correct_tar += (predicted_tar == labels_tar).sum().item()\n",
    "        correct_sev += (predicted_sev == labels_sev).sum().item()\n",
    "        total += labels_tar.size(0)\n",
    "    # Epoch metrics\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    epoch_acc_tar = correct_tar / total\n",
    "    epoch_acc_sev = correct_sev / total\n",
    "\n",
    "    # Print epoch statistics\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}, \"\n",
    "          f\"Target Accuracy: {epoch_acc_tar:.4f}, Severity Accuracy: {epoch_acc_sev:.4f}\")\n",
    "\n",
    "    # Log metrics to CSV\n",
    "    with open(filename, 'a', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([epoch + 1, epoch_loss, epoch_acc_tar, epoch_acc_sev])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_excel(\"Test_Task_B (1).xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Target</th>\n",
       "      <th>Severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1516</td>\n",
       "      <td>100 +crore hindu+ others  ghar me band h, leki...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3359</td>\n",
       "      <td>jo bhosadiwale shaheen bagh khali nahi kara pa...</td>\n",
       "      <td>I</td>\n",
       "      <td>L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6706</td>\n",
       "      <td>ak bar itihas par lena bhavi jaanÃ¢ÂÂ¤Ã¯Â¸Â</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6472</td>\n",
       "      <td>Le hindu :- ye kab huaÃ°ÂÂÂ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4174</td>\n",
       "      <td>#SupremeCourt Hamare Sath Aisa kab tak Hota ra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                              Tweet Target Severity\n",
       "0  1516  100 +crore hindu+ others  ghar me band h, leki...      O        M\n",
       "1  3359  jo bhosadiwale shaheen bagh khali nahi kara pa...      I        L\n",
       "2  6706      ak bar itihas par lena bhavi jaanÃ¢ÂÂ¤Ã¯Â¸Â    NaN      NaN\n",
       "3  6472                     Le hindu :- ye kab huaÃ°ÂÂÂ    NaN      NaN\n",
       "4  4174  #SupremeCourt Hamare Sath Aisa kab tak Hota ra...    NaN      NaN"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Id        800 non-null    int64 \n",
      " 1   Tweet     800 non-null    object\n",
      " 2   Target    513 non-null    object\n",
      " 3   Severity  513 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 25.1+ KB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Target</th>\n",
       "      <th>Severity</th>\n",
       "      <th>temp</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1516</td>\n",
       "      <td>100 +crore hindu+ others  ghar me band h, leki...</td>\n",
       "      <td>O</td>\n",
       "      <td>M</td>\n",
       "      <td>100 crore hindu others  ghar me band h lekin y...</td>\n",
       "      <td>[0.15994893, -0.26070997, 0.13162813, 0.008903...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3359</td>\n",
       "      <td>jo bhosadiwale shaheen bagh khali nahi kara pa...</td>\n",
       "      <td>I</td>\n",
       "      <td>L</td>\n",
       "      <td>jo bhosadiwale shaheen bagh khali nahi kara pa...</td>\n",
       "      <td>[0.1410188, -0.26113942, 0.08613959, 0.0047014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6706</td>\n",
       "      <td>ak bar itihas par lena bhavi jaanÃ¢ÂÂ¤Ã¯Â¸Â</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ak bar itihas par lena bhavi jaan</td>\n",
       "      <td>[0.082532085, -0.1403043, 0.06848083, -0.00255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6472</td>\n",
       "      <td>Le hindu :- ye kab huaÃ°ÂÂÂ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>le hindu  ye kab hua</td>\n",
       "      <td>[0.18784569, -0.32329723, 0.12872386, 0.023461...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                              Tweet Target Severity  \\\n",
       "0  1516  100 +crore hindu+ others  ghar me band h, leki...      O        M   \n",
       "1  3359  jo bhosadiwale shaheen bagh khali nahi kara pa...      I        L   \n",
       "2  6706      ak bar itihas par lena bhavi jaanÃ¢ÂÂ¤Ã¯Â¸Â    NaN      NaN   \n",
       "3  6472                     Le hindu :- ye kab huaÃ°ÂÂÂ    NaN      NaN   \n",
       "\n",
       "                                                temp  \\\n",
       "0  100 crore hindu others  ghar me band h lekin y...   \n",
       "1  jo bhosadiwale shaheen bagh khali nahi kara pa...   \n",
       "2                  ak bar itihas par lena bhavi jaan   \n",
       "3                               le hindu  ye kab hua   \n",
       "\n",
       "                                            word2vec  \n",
       "0  [0.15994893, -0.26070997, 0.13162813, 0.008903...  \n",
       "1  [0.1410188, -0.26113942, 0.08613959, 0.0047014...  \n",
       "2  [0.082532085, -0.1403043, 0.06848083, -0.00255...  \n",
       "3  [0.18784569, -0.32329723, 0.12872386, 0.023461...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['temp'] = test_data['Tweet'].apply(lambda x: clean_text_round1(x))\n",
    "test_data['word2vec'] = test_data['temp'].apply(lambda x: sentence_vector(x,w2v_model)) \n",
    "test_data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_map = {'I': 1, 'O': 2, 'R': 3}\n",
    "test_data['Target'] = test_data['Target'].map(target_map)\n",
    "\n",
    "# Encode Severity column\n",
    "severity_map = {'L': 1, 'M': 2, 'H': 3}\n",
    "test_data['Severity'] = test_data['Severity'].map(severity_map)\n",
    "\n",
    "# Replace NaN in Target and Severity where Hate == 0\n",
    "test_data['Target'] = test_data['Target'].fillna(0)\n",
    "test_data['Severity'] = test_data['Severity'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Target</th>\n",
       "      <th>Severity</th>\n",
       "      <th>temp</th>\n",
       "      <th>word2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1516</td>\n",
       "      <td>100 +crore hindu+ others  ghar me band h, leki...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100 crore hindu others  ghar me band h lekin y...</td>\n",
       "      <td>[0.15994893, -0.26070997, 0.13162813, 0.008903...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3359</td>\n",
       "      <td>jo bhosadiwale shaheen bagh khali nahi kara pa...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jo bhosadiwale shaheen bagh khali nahi kara pa...</td>\n",
       "      <td>[0.1410188, -0.26113942, 0.08613959, 0.0047014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6706</td>\n",
       "      <td>ak bar itihas par lena bhavi jaanÃ¢ÂÂ¤Ã¯Â¸Â</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ak bar itihas par lena bhavi jaan</td>\n",
       "      <td>[0.082532085, -0.1403043, 0.06848083, -0.00255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6472</td>\n",
       "      <td>Le hindu :- ye kab huaÃ°ÂÂÂ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>le hindu  ye kab hua</td>\n",
       "      <td>[0.18784569, -0.32329723, 0.12872386, 0.023461...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4174</td>\n",
       "      <td>#SupremeCourt Hamare Sath Aisa kab tak Hota ra...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>hamare sath aisa kab tak hota rahega kab tak ...</td>\n",
       "      <td>[0.1141099, -0.20440762, 0.08897267, 0.0122381...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>7512</td>\n",
       "      <td>Dekho gt ne rcb ko haraya tha uska badla dhoni...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dekho gt ne rcb ko haraya tha uska badla dhoni...</td>\n",
       "      <td>[0.1607585, -0.2658947, 0.12429711, 0.00650333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>7015</td>\n",
       "      <td>Jarur koi dukhi hoga feku ujjawala yojna KaÃ°Â...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jarur koi dukhi hoga feku ujjawala yojna ka</td>\n",
       "      <td>[0.09407962, -0.1693515, 0.07414168, 0.0095383...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>5410</td>\n",
       "      <td>Jaag Muslim Kab Jaagay Ga? #hijab #Mannat #Kar...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>jaag muslim kab jaagay ga          httpstcoq5y...</td>\n",
       "      <td>[0.11090233, -0.1911797, 0.09437272, 0.0159871...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>7954</td>\n",
       "      <td>Manish Kashyap ko jail mai dalo ð¡ð¡ð¡ð¡</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>manish kashyap ko jail mai dalo</td>\n",
       "      <td>[0.10542921, -0.1757741, 0.08508334, -0.001642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>555</td>\n",
       "      <td>Kash pahle hi Modi ji  China  or Americ  or It...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>kash pahle hi modi ji  china  or americ  or it...</td>\n",
       "      <td>[0.18730119, -0.30109623, 0.14690232, 0.006379...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id                                              Tweet  Target  \\\n",
       "0    1516  100 +crore hindu+ others  ghar me band h, leki...     2.0   \n",
       "1    3359  jo bhosadiwale shaheen bagh khali nahi kara pa...     1.0   \n",
       "2    6706      ak bar itihas par lena bhavi jaanÃ¢ÂÂ¤Ã¯Â¸Â     0.0   \n",
       "3    6472                     Le hindu :- ye kab huaÃ°ÂÂÂ     0.0   \n",
       "4    4174  #SupremeCourt Hamare Sath Aisa kab tak Hota ra...     0.0   \n",
       "..    ...                                                ...     ...   \n",
       "795  7512  Dekho gt ne rcb ko haraya tha uska badla dhoni...     2.0   \n",
       "796  7015  Jarur koi dukhi hoga feku ujjawala yojna KaÃ°Â...     0.0   \n",
       "797  5410  Jaag Muslim Kab Jaagay Ga? #hijab #Mannat #Kar...     0.0   \n",
       "798  7954   Manish Kashyap ko jail mai dalo ð¡ð¡ð¡ð¡     1.0   \n",
       "799   555  Kash pahle hi Modi ji  China  or Americ  or It...     0.0   \n",
       "\n",
       "     Severity                                               temp  \\\n",
       "0         2.0  100 crore hindu others  ghar me band h lekin y...   \n",
       "1         1.0  jo bhosadiwale shaheen bagh khali nahi kara pa...   \n",
       "2         0.0                  ak bar itihas par lena bhavi jaan   \n",
       "3         0.0                               le hindu  ye kab hua   \n",
       "4         0.0   hamare sath aisa kab tak hota rahega kab tak ...   \n",
       "..        ...                                                ...   \n",
       "795       1.0  dekho gt ne rcb ko haraya tha uska badla dhoni...   \n",
       "796       0.0        jarur koi dukhi hoga feku ujjawala yojna ka   \n",
       "797       0.0  jaag muslim kab jaagay ga          httpstcoq5y...   \n",
       "798       1.0                   manish kashyap ko jail mai dalo    \n",
       "799       0.0  kash pahle hi modi ji  china  or americ  or it...   \n",
       "\n",
       "                                              word2vec  \n",
       "0    [0.15994893, -0.26070997, 0.13162813, 0.008903...  \n",
       "1    [0.1410188, -0.26113942, 0.08613959, 0.0047014...  \n",
       "2    [0.082532085, -0.1403043, 0.06848083, -0.00255...  \n",
       "3    [0.18784569, -0.32329723, 0.12872386, 0.023461...  \n",
       "4    [0.1141099, -0.20440762, 0.08897267, 0.0122381...  \n",
       "..                                                 ...  \n",
       "795  [0.1607585, -0.2658947, 0.12429711, 0.00650333...  \n",
       "796  [0.09407962, -0.1693515, 0.07414168, 0.0095383...  \n",
       "797  [0.11090233, -0.1911797, 0.09437272, 0.0159871...  \n",
       "798  [0.10542921, -0.1757741, 0.08508334, -0.001642...  \n",
       "799  [0.18730119, -0.30109623, 0.14690232, 0.006379...  \n",
       "\n",
       "[800 rows x 6 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"\n",
    "        Custom Dataset for Word2Vec inputs with multi-target labels.\n",
    "\n",
    "        Args:\n",
    "        - dataframe (pd.DataFrame): Input data containing word2vec vectors and target labels.\n",
    "        \"\"\"\n",
    "        self.data = dataframe\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Extract the input vector and labels\n",
    "        vector = torch.tensor(self.data.iloc[index]['word2vec'], dtype=torch.float32)\n",
    "        return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = TestDataset(test_data)\n",
    "Sev_outputs = [] \n",
    "target_outputs = []\n",
    "for i in range(dataset_test.__len__()):\n",
    "    input = dataset_test[i]  # Get the input data\n",
    "    input = input.unsqueeze(0)  # Add batch dimension (1, features) if needed\n",
    "    outputs_tar, outputs_sev = Qmodel(input)  # Get softmax output\n",
    "    binary_pred = torch.argmax(outputs_tar, dim=-1).item()  \n",
    "    binary_pred2 = torch.argmax(outputs_sev, dim=-1).item()  \n",
    "    target_outputs.append(binary_pred)\n",
    "    Sev_outputs.append(binary_pred2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Target_pred'] = target_outputs\n",
    "test_data['Severity_pred'] = Sev_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def predict_and_evaluate(test_data):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a multi-label classification model on test data.\n",
    "    \n",
    "    Args:\n",
    "    - test_data (pd.DataFrame): DataFrame containing the ground truth labels ('Hate', 'Fake') \n",
    "                                and the predicted labels ('Hate_pred', 'Fake_pred').\n",
    "\n",
    "    Returns:\n",
    "    - None: Prints classification reports for each target column.\n",
    "    \"\"\"\n",
    "    required_columns = ['Target', 'Severity', 'Target_pred', 'Severity_pred']\n",
    "    missing_columns = [col for col in required_columns if col not in test_data.columns]\n",
    "    if missing_columns:\n",
    "        raise KeyError(f\"The following required columns are missing in the dataset: {missing_columns}\")\n",
    "    \n",
    "    # Replace NaN in Target and Severity where Hate == 0\n",
    "    test_data['Target'] = test_data['Target'].fillna(0)\n",
    "    test_data['Severity'] = test_data['Severity'].fillna(0)\n",
    "    \n",
    "    # Extract true labels and predicted labels\n",
    "    y_test = test_data[['Target', 'Severity']].astype(int)  # Convert to integers if not already\n",
    "    y_pred = test_data[['Target_pred', 'Severity_pred']].astype(int)\n",
    "    \n",
    "    # Evaluate each target separately\n",
    "    for column in y_test.columns:\n",
    "        print(f\"\\nClassification Report for {column}:\")\n",
    "        print(classification_report(y_test[column], y_pred[f\"{column}_pred\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Target:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       287\n",
      "           1       0.02      0.07      0.04       132\n",
      "           2       0.00      0.00      0.00       294\n",
      "           3       0.14      0.70      0.23        87\n",
      "\n",
      "    accuracy                           0.09       800\n",
      "   macro avg       0.04      0.19      0.07       800\n",
      "weighted avg       0.02      0.09      0.03       800\n",
      "\n",
      "\n",
      "Classification Report for Severity:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       287\n",
      "           1       0.00      0.00      0.00       255\n",
      "           2       0.40      0.71      0.51       190\n",
      "           3       0.08      0.51      0.13        68\n",
      "\n",
      "    accuracy                           0.21       800\n",
      "   macro avg       0.12      0.31      0.16       800\n",
      "weighted avg       0.10      0.21      0.13       800\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\naman\\OneDrive\\Documents\\Speed-test\\lulc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naman\\OneDrive\\Documents\\Speed-test\\lulc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naman\\OneDrive\\Documents\\Speed-test\\lulc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naman\\OneDrive\\Documents\\Speed-test\\lulc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naman\\OneDrive\\Documents\\Speed-test\\lulc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\naman\\OneDrive\\Documents\\Speed-test\\lulc\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "predict_and_evaluate(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
